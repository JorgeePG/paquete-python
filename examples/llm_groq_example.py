#!/usr/bin/env python3
"""
Ejemplo de uso del cliente LLM de Groq para an√°lisis de configuraciones T8.
"""

import json
import os
from pathlib import Path

from llm_client import GroqLLMClient


def load_config_data(config_path: str = "llm/config.json") -> dict:
    """Carga los datos de configuraci√≥n desde un archivo JSON."""
    config_file = Path(config_path)
    if not config_file.exists():
        raise FileNotFoundError(f"No se encontr√≥ el archivo: {config_path}")

    with open(config_file, encoding="utf-8") as f:
        return json.load(f)


def analyze_t8_configuration_example() -> None:
    """Ejemplo de an√°lisis de configuraci√≥n T8."""
    print("üîç Ejemplo: An√°lisis de configuraci√≥n TWave T8")
    print("=" * 50)

    try:
        # Inicializar el cliente (necesitas establecer GROQ_API_KEY)
        client = GroqLLMClient()

        # Cargar datos de configuraci√≥n
        config_data = load_config_data()

        print("üìã Analizando configuraci√≥n...")

        # Realizar an√°lisis
        resultado = client.analyze_t8_configuration(
            config_data=config_data, temperature=0.6, max_tokens=4096
        )

        print("\nüìä RESULTADO DEL AN√ÅLISIS:")
        print("-" * 30)
        print(resultado)

    except Exception as e:
        print(f"‚ùå Error: {e}")
        print("\nüí° Aseg√∫rate de:")
        print("  1. Establecer la variable GROQ_API_KEY")
        print("  2. Tener el archivo de configuraci√≥n en llm/config.json")


def streaming_example() -> None:
    """Ejemplo de uso en modo streaming."""
    print("\nüîÑ Ejemplo: An√°lisis en modo streaming")
    print("=" * 50)

    try:
        client = GroqLLMClient()
        config_data = load_config_data()

        print("üìã Analizando configuraci√≥n (streaming)...")
        print("\nüìä RESULTADO (streaming):")
        print("-" * 30)

        # Usar streaming para ver la respuesta en tiempo real
        for chunk in client.analyze_t8_configuration(
            config_data=config_data, stream=True, temperature=0.6
        ):
            print(chunk, end="", flush=True)

        print("\n" + "=" * 50)

    except Exception as e:
        print(f"‚ùå Error: {e}")


def custom_question_example() -> None:
    """Ejemplo de pregunta personalizada."""
    print("\n‚ùì Ejemplo: Pregunta personalizada")
    print("=" * 50)

    try:
        client = GroqLLMClient()
        config_data = load_config_data()

        # Convertir config a string para usar como contexto
        context = json.dumps(config_data, indent=2)

        pregunta = (
            "¬øCu√°les son los puntos de medici√≥n m√°s cr√≠ticos en esta "
            "configuraci√≥n y qu√© par√°metros monitorizan?"
        )

        print(f"ü§î Pregunta: {pregunta}")
        print("\nüìù Respuesta:")
        print("-" * 30)

        respuesta = client.ask_custom_question(
            question=pregunta, context=f"Configuraci√≥n T8:\n{context}", temperature=0.7
        )

        print(respuesta)

    except Exception as e:
        print(f"‚ùå Error: {e}")


def model_switching_example() -> None:
    """Ejemplo de cambio de modelo."""
    print("\nüîÑ Ejemplo: Cambio de modelo")
    print("=" * 50)

    try:
        client = GroqLLMClient()

        print(f"üì¶ Modelo actual: {client.model}")
        print(f"üìã Modelos disponibles: {client.get_available_models()}")

        # Cambiar a un modelo diferente
        client.change_model("llama3-8b-8192")
        print(f"‚úÖ Modelo cambiado a: {client.model}")

        # Hacer una pregunta simple con el nuevo modelo
        respuesta = client.ask_custom_question(
            "Explica brevemente qu√© es el sistema TWave T8.",
            temperature=0.5,
            max_tokens=500,
        )

        print("\nüìù Respuesta con nuevo modelo:")
        print("-" * 30)
        print(respuesta)

    except Exception as e:
        print(f"‚ùå Error: {e}")


def main() -> None:
    """Funci√≥n principal que ejecuta todos los ejemplos."""
    print("üöÄ Ejemplos de uso del Cliente LLM Groq para TWave T8")
    print("=" * 60)

    # Verificar API key
    if not os.getenv("GROQ_API_KEY"):
        print("‚ö†Ô∏è  ADVERTENCIA: No se encontr√≥ GROQ_API_KEY")
        print("   Establece la variable de entorno antes de ejecutar:")
        print("   export GROQ_API_KEY='tu_api_key_aqui'")
        print()

    # Ejecutar ejemplos
    analyze_t8_configuration_example()
    streaming_example()
    custom_question_example()
    model_switching_example()

    print("\n‚úÖ ¬°Ejemplos completados!")
    print("\nüí° Consejos:")
    print("  - Usa temperature=0.6 para an√°lisis t√©cnicos")
    print("  - Usa streaming=True para respuestas largas")
    print("  - Prueba diferentes modelos seg√∫n tus necesidades")


if __name__ == "__main__":
    main()
