"""
Procesador de fragmentos con an√°lisis LLM y agregaci√≥n.
Implementa la estrategia "Divide y Vencer√°s" completa.
"""

from collections.abc import Generator
from typing import TYPE_CHECKING

from llm_client.api_doc_fragmenter import ApiDocFragmenter
from llm_client.cache import ChunkCache
from llm_client.chunking import ConfigChunk, ConfigChunker
from llm_client.model_selector import ModelSelector

if TYPE_CHECKING:
    from llm_client.groq_client import GroqLLMClient


class ChunkedAnalyzer:
    """Analiza configuraciones por fragmentos con cach√© y agregaci√≥n."""

    def __init__(
        self, llm_client: "GroqLLMClient", api_definitions: str | None = None
    ) -> None:
        """
        Inicializa el analizador de fragmentos.

        Args:
            llm_client: Cliente LLM (GroqLLMClient)
            api_definitions: Definiciones de la API
        """
        self.llm_client = llm_client
        self.api_definitions = api_definitions
        self.cache = ChunkCache()
        self.chunker = ConfigChunker()
        self.verbose = False  # Por defecto no verboso

    def analyze_config_chunked(
        self,
        config_data: dict,
        temperature: float = 0.6,
        max_cache_age_hours: float = 24.0,
        stream: bool = False,
        verbose: bool = True,
    ) -> str | Generator[str]:
        """
        Analiza una configuraci√≥n usando la estrategia de fragmentaci√≥n.

        Proceso:
        1. Fragmenta el config.json en partes l√≥gicas
        2. Analiza cada fragmento (usa cach√© si est√° disponible)
        3. Agrega todos los an√°lisis parciales en uno final

        Args:
            config_data: Diccionario con la configuraci√≥n
            temperature: Temperatura del modelo
            max_cache_age_hours: Edad m√°xima del cach√© en horas
            stream: Si True, retorna generador para streaming
            verbose: Si True, muestra progreso

        Returns:
            An√°lisis completo como string o generador
        """
        # Configurar verbosidad para este an√°lisis
        self.verbose = verbose
        
        # 1. Fragmentar configuraci√≥n
        if verbose:
            print("üì¶ Fragmentando configuraci√≥n...")

        chunks = self.chunker.chunk_config(config_data)
        config_uid = self.chunker.get_config_uid(config_data)

        if verbose:
            print(f"   ‚úÖ {len(chunks)} fragmentos creados")

        # 2. Analizar cada fragmento (con cach√©)
        partial_analyses = []
        cache_hits = 0
        cache_misses = 0

        for idx, chunk in enumerate(chunks, 1):
            if verbose:
                print(
                    f"\nüîç Analizando fragmento {idx}/{len(chunks)}: {chunk.chunk_type}"
                )

            # Intentar obtener del cach√©
            cached = self.cache.get(chunk.chunk_id, max_age_hours=max_cache_age_hours)

            if cached:
                # Usar an√°lisis cacheado
                if verbose:
                    print("   ‚ö° Usando an√°lisis cacheado")
                partial_analyses.append(
                    {
                        "chunk_type": chunk.chunk_type,
                        "description": chunk.description,
                        "analysis": cached.analysis,
                    }
                )
                cache_hits += 1
            else:
                # Generar nuevo an√°lisis
                if verbose:
                    print("   ü§ñ Generando nuevo an√°lisis...")

                analysis = self._analyze_chunk(chunk, temperature)

                # Guardar en cach√©
                self.cache.set(
                    chunk_id=chunk.chunk_id,
                    chunk_type=chunk.chunk_type,
                    analysis=analysis,
                    config_uid=config_uid,
                    model=self.llm_client.model,
                    temperature=temperature,
                )

                partial_analyses.append(
                    {
                        "chunk_type": chunk.chunk_type,
                        "description": chunk.description,
                        "analysis": analysis,
                    }
                )
                cache_misses += 1

        if verbose:
            print(f"\nüìä Cach√©: {cache_hits} hits, {cache_misses} misses")
            print(f"üíæ Tama√±o del cach√©: {self.cache.get_size_mb():.2f} MB")

        # 3. Agregar an√°lisis parciales
        if verbose:
            print("\nüîÑ Agregando an√°lisis parciales...")

        final_analysis = self._aggregate_analyses(
            partial_analyses, config_data, temperature, stream
        )

        if verbose and not stream:
            print("   ‚úÖ An√°lisis completo generado\n")

        return final_analysis

    def _analyze_chunk(self, chunk: ConfigChunk, temperature: float) -> str:
        """
        Analiza un fragmento espec√≠fico usando el LLM.

        Args:
            chunk: Fragmento a analizar
            temperature: Temperatura del modelo

        Returns:
            An√°lisis del fragmento
        """

        # Seleccionar modelo √≥ptimo para este fragmento
        content_size = len(str(chunk.content))
        model_config = ModelSelector.select_for_chunk_analysis(
            chunk.chunk_type, content_size
        )

        if self.verbose:
            print(
                f"  ü§ñ Modelo: {model_config.name} "
                f"(tier {model_config.cost_tier}, {content_size} chars)"
            )

        # Construir prompt espec√≠fico para el fragmento
        prompt = self._build_chunk_prompt(chunk)

        # Generar an√°lisis (sin streaming) usando el modelo seleccionado
        response = self.llm_client._generate_completion(
            prompt=prompt,
            temperature=temperature,
            max_tokens=min(2048, model_config.max_tokens),
            stream=False,
            model=model_config.name,  # Modelo din√°mico
        )

        return response

    def _build_chunk_prompt(self, chunk: ConfigChunk) -> str:
        """
        Construye un prompt espec√≠fico para analizar un fragmento.
        Incluye solo la documentaci√≥n API relevante para ese tipo de fragmento.

        Args:
            chunk: Fragmento a analizar

        Returns:
            Prompt formateado con contexto API optimizado
        """
        import json as json_module

        chunk_json = json_module.dumps(chunk.content, indent=2)

        # Obtener contexto API relevante para este tipo de fragmento
        api_context = ApiDocFragmenter.get_relevant_context(chunk.chunk_type)

        # Prompts base con contexto API espec√≠fico
        prompts = {
            "machines_summary": f"""
Eres un experto en sistemas TWave T8. Analiza el siguiente resumen de m√°quinas:

{api_context}

**DATOS A ANALIZAR:**
```json
{chunk_json}
```

Proporciona una descripci√≥n concisa de:
- N√∫mero de m√°quinas configuradas
- Nombres y tags de las m√°quinas
- Cantidad de puntos de medici√≥n por m√°quina
- Estados y estrategias configuradas

S√© breve y directo.""",
            "measurement_points": f"""
Eres un experto en sistemas TWave T8. Analiza los siguientes puntos de medici√≥n:

{api_context}

**DATOS A ANALIZAR:**
```json
{chunk_json}
```

Describe brevemente:
- Tipos de sensores y su configuraci√≥n (seg√∫n el campo `type` y `mode`)
- Ubicaciones de medici√≥n principales (seg√∫n `path` y `component_id`)
- Configuraci√≥n de entrada f√≠sica (si aplica)

S√© conciso y t√©cnico.""",
            "processing_modes": f"""
Eres un experto en sistemas TWave T8. Analiza los siguientes modos de procesamiento:

{api_context}

**DATOS A ANALIZAR:**
```json
{chunk_json}
```

Explica brevemente (usando el contexto API):
- Configuraciones FFT: sample_rate, max_freq, bins, averages
- Tipo de procesamiento (type) y su significado
- Niveles de integraci√≥n aplicados (integrate_sp)
- Configuraci√≥n de guardado (save_sp, save_wf)

S√© t√©cnico y preciso.""",
            "calculated_params": f"""
Eres un experto en sistemas TWave T8. Analiza los siguientes par√°metros calculados:

{api_context}

**DATOS A ANALIZAR:**
```json
{chunk_json}
```

Describe (interpretando seg√∫n el contexto API):
- Tipo de c√°lculo (type) y su significado exacto
- Configuraci√≥n de alarmas por estado (si existen)
- Bandas espectrales (spectral_bands) si aplican
- Niveles de integraci√≥n y detecci√≥n aplicados

S√© preciso y t√©cnico.""",
            "operational_states": f"""
Eres un experto en sistemas TWave T8. Analiza los siguientes estados operativos:

{api_context}

**DATOS A ANALIZAR:**
```json
{chunk_json}
```

Explica (usando el contexto API):
- Nombres y condiciones de cada estado
- L√≥gica de las condiciones (expresiones con speed, params)
- Prop√≥sito de cada estado en el monitoreo

S√© conciso.""",
            "storage_strategies": f"""
Eres un experto en sistemas TWave T8. Analiza las siguientes estrategias de
almacenamiento:

{api_context}

**DATOS A ANALIZAR:**
```json
{chunk_json}
```

Describe (interpretando el campo `type` seg√∫n contexto API):
- Tipo de disparador de cada estrategia
- Configuraci√≥n espec√≠fica (cron_line, mon_period, state transitions, alarm levels)
- Cu√°ndo y por qu√© se almacenan datos

S√© t√©cnico.""",
            "system_properties": f"""
Eres un experto en sistemas TWave T8. Analiza las siguientes propiedades del sistema:

{api_context}

**DATOS A ANALIZAR:**
```json
{chunk_json}
```

Resume (usando el contexto API):
- Propiedades f√≠sicas (properties) y sus IDs
- Unidades de medida (units) con factores de conversi√≥n
- Relaciones entre properties y units (property_id)

S√© directo y t√©cnico.""",
        }

        # Fallback con contexto gen√©rico
        return prompts.get(
            chunk.chunk_type,
            f"""
Eres un experto en sistemas TWave T8.

{api_context}

**FRAGMENTO A ANALIZAR:**
Tipo: {chunk.chunk_type}
Descripci√≥n: {chunk.description}

```json
{chunk_json}
```

Proporciona un an√°lisis breve y conciso bas√°ndote en el contexto API proporcionado.""",
        )

    def _aggregate_analyses(
        self,
        partial_analyses: list[dict],
        config_data: dict,
        temperature: float,
        stream: bool,
    ) -> str | Generator[str]:
        """
        Agrega todos los an√°lisis parciales en uno final y coherente.

        Args:
            partial_analyses: Lista de an√°lisis parciales
            config_data: Configuraci√≥n original (para contexto)
            temperature: Temperatura del modelo
            stream: Si True, retorna generador

        Returns:
            An√°lisis final agregado
        """
        # Construir contexto con todos los an√°lisis parciales
        context = "**AN√ÅLISIS PARCIALES DE LA CONFIGURACI√ìN T8:**\n\n"

        for idx, analysis in enumerate(partial_analyses, 1):
            context += f"## {idx}. {analysis['description']}\n"
            context += f"Tipo: {analysis['chunk_type']}\n\n"
            context += f"{analysis['analysis']}\n\n"
            context += "---\n\n"

        # Agregar informaci√≥n b√°sica de la config
        machines = config_data.get("machines", [])
        machine_names = [m.get("tag", "Unknown") for m in machines]
        context += f"**M√°quinas en la configuraci√≥n:** {', '.join(machine_names)}\n\n"

        # Prompt para agregaci√≥n final
        aggregation_prompt = f"""
Eres un experto en el sistema de monitoreo de vibraci√≥n TWave T8.

A continuaci√≥n, te proporciono an√°lisis parciales de diferentes secciones de un
archivo de configuraci√≥n. Tu tarea es **sintetizar estos an√°lisis en una √∫nica
explicaci√≥n coherente y completa** para el usuario.

{context}

**TAREA:**

Genera un an√°lisis completo y bien estructurado de la configuraci√≥n, integrando
toda la informaci√≥n de los an√°lisis parciales.

**FORMATO DE SALIDA:**

Estructura tu respuesta usando encabezados Markdown:

## üìä Resumen General

## üè≠ M√°quinas Configuradas

## üìç Puntos de Medici√≥n Principales

## ‚öôÔ∏è Modos de Procesamiento

## üìà Par√°metros Monitoreados

## üîÑ Estados Operativos

## üíæ Estrategias de Almacenamiento

## üéØ Conclusiones

Proporciona informaci√≥n clara, concisa y profesional. Evita repetir informaci√≥n
innecesariamente. Enf√≥cate en los aspectos m√°s relevantes para el monitoreo de
vibraci√≥n y la operaci√≥n del sistema.
"""

        # Seleccionar modelo potente para agregaci√≥n
        total_size = sum(len(a["analysis"]) for a in partial_analyses)
        model_config = ModelSelector.select_for_aggregation(
            num_fragments=len(partial_analyses), total_size=total_size
        )

        if self.verbose:
            print(
                f"\nüîÑ Agregando {len(partial_analyses)} an√°lisis parciales..."
            )
            print(
                f"ü§ñ Modelo de agregaci√≥n: {model_config.name} "
                f"(tier {model_config.cost_tier}, {total_size} chars)"
            )

        # Generar agregaci√≥n final usando modelo potente
        return self.llm_client._generate_completion(
            prompt=aggregation_prompt,
            temperature=temperature,
            max_tokens=min(4096, model_config.max_tokens),
            stream=stream,
            model=model_config.name,  # Modelo din√°mico para agregaci√≥n
        )

    def clear_cache(self, config_uid: str | None = None) -> int:
        """
        Limpia el cach√©.

        Args:
            config_uid: Si se proporciona, solo limpia esa configuraci√≥n.
                       Si es None, limpia todo el cach√©.

        Returns:
            N√∫mero de entradas eliminadas
        """
        if config_uid:
            return self.cache.clear_config(config_uid)
        else:
            return self.cache.clear_all()

    def get_cache_stats(self) -> dict:
        """
        Obtiene estad√≠sticas del cach√©.

        Returns:
            Diccionario con estad√≠sticas
        """
        return self.cache.get_stats()
