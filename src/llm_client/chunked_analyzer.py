"""
Procesador de fragmentos con an√°lisis LLM y agregaci√≥n.
Implementa la estrategia "Divide y Vencer√°s" completa.
"""

from collections.abc import Generator
from typing import TYPE_CHECKING

from llm_client.api_doc_fragmenter import ApiDocFragmenter
from llm_client.cache import ChunkCache
from llm_client.chunking import ConfigChunk, ConfigChunker
from llm_client.model_selector import ModelSelector

if TYPE_CHECKING:
    from llm_client.groq_client import GroqLLMClient


class ChunkedAnalyzer:
    """Analiza configuraciones por fragmentos con cach√© y agregaci√≥n."""

    def __init__(
        self, llm_client: "GroqLLMClient", api_definitions: str | None = None
    ) -> None:
        """
        Inicializa el analizador de fragmentos.

        Args:
            llm_client: Cliente LLM (GroqLLMClient)
            api_definitions: Definiciones de la API
        """
        self.llm_client = llm_client
        self.api_definitions = api_definitions
        self.cache = ChunkCache()
        self.chunker = ConfigChunker()
        self.verbose = False  # Por defecto no verboso

    def analyze_config_chunked(
        self,
        config_data: dict,
        temperature: float = 0.6,
        max_cache_age_hours: float = 24.0,
        stream: bool = False,
        verbose: bool = True,
    ) -> str | Generator[str]:
        """
        Analiza una configuraci√≥n usando la estrategia de fragmentaci√≥n.

        Proceso:
        1. Fragmenta el config.json en partes l√≥gicas
        2. Analiza cada fragmento (usa cach√© si est√° disponible)
        3. Agrega todos los an√°lisis parciales en uno final

        Args:
            config_data: Diccionario con la configuraci√≥n
            temperature: Temperatura del modelo
            max_cache_age_hours: Edad m√°xima del cach√© en horas
            stream: Si True, retorna generador para streaming
            verbose: Si True, muestra progreso

        Returns:
            An√°lisis completo como string o generador
        """
        # Configurar verbosidad para este an√°lisis
        self.verbose = verbose
        
        # 1. Fragmentar configuraci√≥n
        if verbose:
            print("üì¶ Fragmentando configuraci√≥n...")

        chunks = self.chunker.chunk_config(config_data)
        config_uid = self.chunker.get_config_uid(config_data)

        if verbose:
            print(f"   ‚úÖ {len(chunks)} fragmentos creados")

        # 2. Analizar cada fragmento (con cach√©)
        partial_analyses = []
        cache_hits = 0
        cache_misses = 0

        for idx, chunk in enumerate(chunks, 1):
            if verbose:
                print(
                    f"\nüîç Analizando fragmento {idx}/{len(chunks)}: {chunk.chunk_type}"
                )

            # Intentar obtener del cach√©
            cached = self.cache.get(chunk.chunk_id, max_age_hours=max_cache_age_hours)

            if cached:
                # Usar an√°lisis cacheado
                if verbose:
                    print("   ‚ö° Usando an√°lisis cacheado")
                partial_analyses.append(
                    {
                        "chunk_type": chunk.chunk_type,
                        "description": chunk.description,
                        "analysis": cached.analysis,
                    }
                )
                cache_hits += 1
            else:
                # Generar nuevo an√°lisis
                if verbose:
                    print("   ü§ñ Generando nuevo an√°lisis...")

                analysis = self._analyze_chunk(chunk, temperature)

                # Guardar en cach√©
                self.cache.set(
                    chunk_id=chunk.chunk_id,
                    chunk_type=chunk.chunk_type,
                    analysis=analysis,
                    config_uid=config_uid,
                    model=self.llm_client.model,
                    temperature=temperature,
                )

                partial_analyses.append(
                    {
                        "chunk_type": chunk.chunk_type,
                        "description": chunk.description,
                        "analysis": analysis,
                    }
                )
                cache_misses += 1

        if verbose:
            print(f"\nüìä Cach√©: {cache_hits} hits, {cache_misses} misses")
            print(f"üíæ Tama√±o del cach√©: {self.cache.get_size_mb():.2f} MB")

        # 3. Agregar an√°lisis parciales
        if verbose:
            print("\nüîÑ Agregando an√°lisis parciales...")

        final_analysis = self._aggregate_analyses(
            partial_analyses, config_data, temperature, stream
        )

        if verbose and not stream:
            print("   ‚úÖ An√°lisis completo generado\n")

        return final_analysis

    def _analyze_chunk(self, chunk: ConfigChunk, temperature: float) -> str:
        """
        Analiza un fragmento espec√≠fico usando el LLM.

        Args:
            chunk: Fragmento a analizar
            temperature: Temperatura del modelo

        Returns:
            An√°lisis del fragmento
        """

        # Seleccionar modelo √≥ptimo para este fragmento
        content_size = len(str(chunk.content))
        model_config = ModelSelector.select_for_chunk_analysis(
            chunk.chunk_type, content_size
        )

        if self.verbose:
            print(
                f"  ü§ñ Modelo: {model_config.name} "
                f"(tier {model_config.cost_tier}, {content_size} chars)"
            )

        # Construir prompt espec√≠fico para el fragmento
        prompt = self._build_chunk_prompt(chunk)

        # Generar an√°lisis (sin streaming) usando el modelo seleccionado
        response = self.llm_client._generate_completion(
            prompt=prompt,
            temperature=temperature,
            max_tokens=min(1500, model_config.max_tokens),  # Reducido de 2048 a 1500
            stream=False,
            model=model_config.name,  # Modelo din√°mico
        )

        return response

    def _build_chunk_prompt(self, chunk: ConfigChunk) -> str:
        """
        Construye un prompt espec√≠fico para analizar un fragmento.
        Incluye solo la documentaci√≥n API relevante para ese tipo de fragmento.

        Args:
            chunk: Fragmento a analizar

        Returns:
            Prompt formateado con contexto API optimizado
        """
        import json as json_module

        chunk_json = json_module.dumps(chunk.content, indent=2)

        # Obtener contexto API relevante para este tipo de fragmento
        api_context = ApiDocFragmenter.get_relevant_context(chunk.chunk_type)

        # Prompts base con contexto API espec√≠fico
        prompts = {
            "machines_summary": f"""
Analiza este resumen de m√°quinas T8:

{api_context}

**DATOS:**
```json
{chunk_json}
```

Lista brevemente: m√°quinas, puntos por m√°quina, estados y estrategias.
M√°ximo 300 palabras.""",
            "measurement_points": f"""
Analiza puntos de medici√≥n T8:

{api_context}

**DATOS:**
```json
{chunk_json}
```

Resume: tipos de sensores (type/mode), ubicaciones (path), configuraci√≥n f√≠sica.
Formato tabla compacta. M√°ximo 400 palabras.""",
            "processing_modes": f"""
Analiza modos de procesamiento T8:

{api_context}

**DATOS:**
```json
{chunk_json}
```

Indica: FFT config (sample_rate, max_freq, bins), averages, overlap, window, 
integrate_sp (afecta unidades), save_sp/save_wf.
Formato tabla. M√°ximo 500 palabras.""",
            "calculated_params": f"""
Eres experto en TWave T8. Analiza estos par√°metros calculados:

{api_context}

**DATOS:**
```json
{chunk_json}
```

Para cada punto, indica de forma COMPACTA:
- Par√°metros principales (tag, type, integrate)
- Unidades resultantes (considerando sensor.unit_id e integrate)
- Bandas espectrales si aplica (type 6/9)
- Alarmas configuradas (solo si existen, indicar state_id y valores)

**REGLAS UNIDADES CR√çTICAS:**
- Si sensor.unit_id=14 (¬µm) y integrate=0 ‚Üí resultado en ¬µm
- Si sensor.unit_id=14 (¬µm) y integrate=1 ‚Üí resultado en mm/s
- Si sensor.unit_id=14 (¬µm) y integrate=2 ‚Üí resultado en g

Formato: Lista concisa, evita repetir estructura JSON. M√°ximo 500 palabras.""",
            "operational_states": f"""
Analiza estados operativos T8:

{api_context}

**DATOS:**
```json
{chunk_json}
```

Lista: nombres, condiciones (expresiones con speed/params), prop√≥sito.
M√°ximo 300 palabras.""",
            "storage_strategies": f"""
Analiza estrategias de almacenamiento T8:

{api_context}

**DATOS:**
```json
{chunk_json}
```

Por cada estrategia indica:
- Tipo (type) y qu√© lo dispara:
  * type 0: Tiempo/Cron (cron_line)
  * type 1: Ciclos de monitorizaci√≥n (mon_period)
  * type 2: Cambio de estado (de state1_id a state2_id)
  * type 3: Nivel de alarma de par√°metros (alarm level)
  * type 5: Manual
- Condici√≥n adicional (condition) si existe
- **CR√çTICO:** Menciona qu√© estados o par√°metros est√°n involucrados

Formato tabla. M√°ximo 400 palabras.""",
            "system_properties": f"""
Analiza propiedades del sistema T8:

{api_context}

**DATOS:**
```json
{chunk_json}
```

Resume: propiedades f√≠sicas (properties), unidades (units) con factores de conversi√≥n,
relaciones property_id.
Formato tabla. M√°ximo 300 palabras.""",
        }

        # Fallback con contexto gen√©rico
        return prompts.get(
            chunk.chunk_type,
            f"""
Analiza este fragmento de configuraci√≥n T8:

{api_context}

**Fragmento:** {chunk.chunk_type}
**Descripci√≥n:** {chunk.description}

```json
{chunk_json}
```

An√°lisis breve basado en contexto API. M√°ximo 300 palabras.""",
        )

    def _aggregate_analyses(
        self,
        partial_analyses: list[dict],
        config_data: dict,
        temperature: float,
        stream: bool,
    ) -> str | Generator[str]:
        """
        Agrega todos los an√°lisis parciales en uno final y coherente.
        Optimizado para reducir tokens usando res√∫menes estructurados.

        Args:
            partial_analyses: Lista de an√°lisis parciales
            config_data: Configuraci√≥n original (para contexto)
            temperature: Temperatura del modelo
            stream: Si True, retorna generador

        Returns:
            An√°lisis final agregado
        """
        # Agrupar an√°lisis por tipo para resumen m√°s compacto
        grouped = {}
        for analysis in partial_analyses:
            chunk_type = analysis['chunk_type']
            if chunk_type not in grouped:
                grouped[chunk_type] = []
            grouped[chunk_type].append(analysis)
        
        # Construir contexto COMPACTO con an√°lisis agrupados
        context = "**AN√ÅLISIS DE CONFIGURACI√ìN T8 (Resumen Estructurado):**\n\n"
        
        # Orden l√≥gico de presentaci√≥n
        type_order = [
            "machines_summary",
            "system_properties", 
            "measurement_points",
            "processing_modes",
            "calculated_params",
            "operational_states",
            "storage_strategies"
        ]
        
        for chunk_type in type_order:
            if chunk_type in grouped:
                analyses = grouped[chunk_type]
                context += f"### {chunk_type.replace('_', ' ').title()}\n"
                
                # Si hay m√∫ltiples an√°lisis del mismo tipo, condensarlos
                if len(analyses) > 1:
                    context += f"*({len(analyses)} fragmentos consolidados)*\n\n"
                    # Solo incluir los primeros 2 completos, resumir el resto
                    for analysis in analyses[:2]:
                        context += f"{analysis['analysis']}\n\n"
                    if len(analyses) > 2:
                        context += f"*... y {len(analyses) - 2} fragmentos adicionales del mismo tipo*\n\n"
                else:
                    context += f"{analyses[0]['analysis']}\n\n"
                
                context += "---\n\n"
        
        # Agregar informaci√≥n b√°sica de la config
        machines = config_data.get("machines", [])
        machine_names = [m.get("tag", "Unknown") for m in machines]
        context += f"**M√°quinas:** {', '.join(machine_names)}\n"
        context += f"**Total de fragmentos analizados:** {len(partial_analyses)}\n\n"

        # Prompt OPTIMIZADO para agregaci√≥n final con RELACIONES expl√≠citas
        aggregation_prompt = f"""
Eres un experto en TWave T8. Sintetiza los siguientes an√°lisis parciales en un 
reporte coherente y profesional.

{context}

**RELACIONES CLAVE DEL SISTEMA T8:**

1. **Estados Operativos** ‚Üí definen condiciones de la m√°quina (basados en speed, par√°metros)
2. **Estrategias de Almacenamiento** ‚Üí SE ACTIVAN seg√∫n:
   - Estados operativos (type 2: cambios de estado entre state1_id y state2_id)
   - Niveles de alarma de par√°metros (type 3: seg√∫n nivel alarm)
   - Tiempo/Cron (type 0: cron_line)
   - Ciclos de monitorizaci√≥n (type 1: cada mon_period ciclos)
3. **Par√°metros Calculados** ‚Üí generan alarmas que pueden activar estrategias
4. **Modos de Procesamiento** ‚Üí definen c√≥mo se calculan los par√°metros (FFT, integraci√≥n)

**INSTRUCCIONES:**

Al generar el reporte, EXPLICA EXPL√çCITAMENTE estas relaciones:
- Qu√© estados est√°n definidos y c√≥mo se detectan
- Qu√© estrategias se disparan con cada estado o alarma
- C√≥mo las alarmas de par√°metros activan estrategias de almacenamiento

Usa formato Markdown:

## üìä Resumen General
## üè≠ M√°quinas y Puntos de Medici√≥n
## ‚öôÔ∏è Procesamiento y Par√°metros Calculados
## üîÑ Estados Operativos y sus Condiciones
## üíæ Estrategias de Almacenamiento (y qu√© las activa)
## üéØ Observaciones Clave

**L√≠mite:** M√°ximo 2500 palabras. S√© t√©cnico y explica las RELACIONES."""

        # Seleccionar modelo potente para agregaci√≥n
        total_size = sum(len(a["analysis"]) for a in partial_analyses)
        model_config = ModelSelector.select_for_aggregation(
            num_fragments=len(partial_analyses), total_size=total_size
        )

        if self.verbose:
            print(
                f"\nüîÑ Agregando {len(partial_analyses)} an√°lisis parciales..."
            )
            print(
                f"ü§ñ Modelo de agregaci√≥n: {model_config.name} "
                f"(tier {model_config.cost_tier}, {total_size} chars)"
            )

        # Generar agregaci√≥n final usando modelo potente
        return self.llm_client._generate_completion(
            prompt=aggregation_prompt,
            temperature=temperature,
            max_tokens=min(3000, model_config.max_tokens),  # Reducido de 4096 a 3000
            stream=stream,
            model=model_config.name,  # Modelo din√°mico para agregaci√≥n
        )

    def clear_cache(self, config_uid: str | None = None) -> int:
        """
        Limpia el cach√©.

        Args:
            config_uid: Si se proporciona, solo limpia esa configuraci√≥n.
                       Si es None, limpia todo el cach√©.

        Returns:
            N√∫mero de entradas eliminadas
        """
        if config_uid:
            return self.cache.clear_config(config_uid)
        else:
            return self.cache.clear_all()

    def get_cache_stats(self) -> dict:
        """
        Obtiene estad√≠sticas del cach√©.

        Returns:
            Diccionario con estad√≠sticas
        """
        return self.cache.get_stats()
